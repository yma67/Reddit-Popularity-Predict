{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import re\n",
    "import itertools\n",
    "from time import sleep\n",
    "import sys\n",
    "import numpy\n",
    "import scipy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter\n",
    "with open(\"proj1_data.json\") as fp:\n",
    "    data = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word count, no removal of punctuations\n",
    "# @Param: singleText: text to process, numberOfFeatures: 0, 60, 160?\n",
    "# @Return: vector of count (x in description)\n",
    "def wordCountNaive(singleText, numberOfFeatures): \n",
    "    countNaive = Counter([s.lower() for s in singleText.split()])\n",
    "    \n",
    "    i = 0\n",
    "    returnVector = [0.0 for i in range(0, numberOfFeatures)]\n",
    "    for key, value in countNaive.most_common(numberOfFeatures): \n",
    "        if i == numberOfFeatures: \n",
    "            break\n",
    "        returnVector[i] = float(value)\n",
    "        i = i + 1\n",
    "        \n",
    "    return returnVector\n",
    "\n",
    "\n",
    "# word count, remove punc and stopwords to imporve model\n",
    "# @Param: singleText: text to process, numberOfFeatures: 0, 60, 160?\n",
    "# @Return: vector of count (x in description)\n",
    "def wordCountWithStopwords(singleText, numberOfFeatures): \n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    withoutPunc = tokenizer.tokenize(singleText)\n",
    "    countDict = Counter(s.lower() for s in withoutPunc if s.lower() not in stopwords.words())\n",
    "    \n",
    "    i = 0\n",
    "    returnVector = [0.0 for i in range(0, numberOfFeatures)]\n",
    "    for key, value in countDict.most_common(numberOfFeatures): \n",
    "        if i == numberOfFeatures: \n",
    "            break\n",
    "        returnVector[i] = float(value)\n",
    "        i = i + 1\n",
    "\n",
    "    return returnVector\n",
    "\n",
    "# Test: \n",
    "# print(wordCountWithStopwords([data[8]['text']], 160))\n",
    "# print(data[8]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word pos count, remove punc and stopwords to imporve model\n",
    "# @Param: singleText: text to process\n",
    "# @Return: vector of [verbcount, nouncount, adjcount]\n",
    "def wordPOSCountWithStopwords(singleText): \n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    withoutPunc = tokenizer.tokenize(singleText)\n",
    "    tagged = nltk.pos_tag([s.lower() for s in withoutPunc if s.lower() not in stopwords.words()])\n",
    "    \n",
    "    verbTotal, nounTotal, adjTotal = 0, 0, 0\n",
    "    counts = Counter(tag for wordType, tag in tagged)\n",
    "    totalCount = len(singleText.split())\n",
    "    \n",
    "    for key, value in counts.items(): \n",
    "        if 'NN' in key: \n",
    "            nounTotal = nounTotal + 1\n",
    "        elif 'VB' in key: \n",
    "            verbTotal = verbTotal + 1\n",
    "        elif 'JJ' in key: \n",
    "            adjTotal = adjTotal + 1\n",
    "            \n",
    "    if totalCount > 0: \n",
    "        return [float(verbTotal) / totalCount, float(nounTotal) / totalCount, float(adjTotal) / totalCount]\n",
    "    else: \n",
    "        return [0.0, 0.0, 0.0]\n",
    "# Test: \n",
    "# print(wordPOSCountWithStopwords(data[3]['text']))\n",
    "# print(data[3]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasURL(text): \n",
    "    if re.match(r\"(http://[^ ]+)\", text) != None: \n",
    "        return 1.0\n",
    "    else: \n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pythonListTranspose(xl): \n",
    "    return list(map(list, itertools.zip_longest(*xl)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Parser\n",
    "# @Param: dataVector: sliced original dataset, wordCountFunction: <str> -> ndarray<float>, \n",
    "# wordPOSFunction: str -> list<float>, numberOfTextFeature: 0 to shut down Text Processing (Text Features)\n",
    "# featureType: \n",
    "# @Return: tuple<ndarray, list>: xEngineered, yExtracted: rows: vector<samplePoint>, samplePoint[0->2]: basic Features, \n",
    "# samplePoint[3->162]: text, samplePoint[163->167]: extra\n",
    "def parseFeatures(dataVector, wordCountFunction, numberOfTextFeatures, featureType): \n",
    "    y = []\n",
    "    childrenFeature = []\n",
    "    controversialityFeature = []\n",
    "    isRootFeature = []\n",
    "    processedTextFeature = []\n",
    "    verbFeature = []\n",
    "    nounFeature = []\n",
    "    adjFeature = []\n",
    "    urlFeature = []\n",
    "    identityFeature = []\n",
    "    c = 0\n",
    "    lenV = len(dataVector)\n",
    "    for dataPoint in dataVector: \n",
    "        \n",
    "        # Basic Features\n",
    "        y.append(float(dataPoint['popularity_score']))\n",
    "        if 'children' in featureType: \n",
    "            childrenFeature.append(float(dataPoint['children']))\n",
    "        if 'controv' in featureType: \n",
    "            controversialityFeature.append(float(dataPoint['controversiality']))\n",
    "        identityFeature.append(1.0)\n",
    "        isRootVar = -1.0\n",
    "        if 'isRoot' in featureType: \n",
    "            if dataPoint['is_root'] == True: \n",
    "                isRootVar = 1.0\n",
    "                isRootFeature.append(isRootVar)\n",
    "            else: \n",
    "                isRootVar = 0.0\n",
    "                isRootFeature.append(isRootVar)\n",
    "        \n",
    "        # Text Features: 0 to shut down text feature\n",
    "        if numberOfTextFeatures > 0 and 'text' in featureType: \n",
    "            processedTextFeature.append(wordCountFunction(dataPoint['text'], numberOfTextFeatures))\n",
    "        \n",
    "        # Extra Features\n",
    "        if 'noun' in featureType or 'verb' in featureType or 'adj' in featureType: \n",
    "            wordAnalysis = wordPOSCountWithStopwords(dataPoint['text'])\n",
    "        if 'verb' in featureType: \n",
    "            verbFeature.append(wordAnalysis[0])\n",
    "        if 'noun' in featureType: \n",
    "            nounFeature.append(wordAnalysis[1])\n",
    "        if 'adj' in featureType: \n",
    "            adjFeature.append(wordAnalysis[2])\n",
    "        if 'url' in featureType: \n",
    "            urlFeature.append(hasURL(dataPoint['text']))\n",
    "        \n",
    "        # Process Bar\n",
    "        sys.stdout.write('\\r')\n",
    "        count = int((float(c) / float(lenV)) * 100)\n",
    "        sys.stdout.write(\"[%-20s] %d%%\" % ('='*int(count / 5), count))\n",
    "        sleep(0.001)\n",
    "        sys.stdout.flush()\n",
    "        c = c + 1\n",
    "    if len(processedTextFeature) > 0: \n",
    "        processedTextFeature = pythonListTranspose(processedTextFeature)\n",
    "    returnTotal = [childrenFeature, controversialityFeature, isRootFeature] + processedTextFeature + [verbFeature, nounFeature, adjFeature, urlFeature, identityFeature]\n",
    "    return pythonListTranspose([x for x in returnTotal if len(x) > 0]), pythonListTranspose([y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanSquareError(validationX, validationY, w): \n",
    "    diffenence = numpy.power(numpy.transpose(numpy.subtract(validationY, numpy.matmul(validationX, w)))[0], 2)\n",
    "    return numpy.divide(numpy.sum(diffenence), len(validationY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closedFormLinearRegression(x, y): \n",
    "    xT = numpy.transpose(numpy.array(x))\n",
    "    return numpy.matmul(numpy.matmul(scipy.linalg.inv(numpy.matmul(xT, numpy.array(x))), xT), numpy.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescentLinearRegression(learnRateFunction, x, y, tol): \n",
    "    i = 1\n",
    "    weight = numpy.array([[0.0] for l in range(len(x[0]))])\n",
    "    weightN = numpy.array([[0.0] for l in range(len(x[0]))])\n",
    "    xT = numpy.transpose(x)\n",
    "    xTx = numpy.matmul(xT, x)\n",
    "    xTy = numpy.matmul(xT, y)\n",
    "    while True: \n",
    "        weight = weightN\n",
    "        weightN = numpy.subtract(weight, 2 * learnRateFunction(i) * numpy.subtract(numpy.matmul(xTx, weight), xTy))\n",
    "        i = i + 1\n",
    "        if numpy.linalg.norm(numpy.subtract(weightN, weight), 2) <= tol: \n",
    "            break\n",
    "    return weightN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: comparison of GD and closed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== ] 99%"
     ]
    }
   ],
   "source": [
    "trainFeatures = parseFeatures(data[:10000], wordCountNaive, 0, ['children', 'controv', 'isRoot'])\n",
    "validationFeatures = parseFeatures(data[10000:11000], wordCountNaive, 0, ['children', 'controv', 'isRoot'])\n",
    "testFeatures = parseFeatures(data[11000:12000], wordCountNaive, 0, ['children', 'controv', 'isRoot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of closed form: \n",
      " [[ 0.37536403]\n",
      " [-1.08584747]\n",
      " [-0.22627679]\n",
      " [ 0.82092517]]\n",
      "error of closed form: \n",
      " 1.0203266848431447\n"
     ]
    }
   ],
   "source": [
    "resultClosed = closedFormLinearRegression(trainFeatures[0], trainFeatures[1])\n",
    "errorClosed = meanSquareError(validationFeatures[0], validationFeatures[1], resultClosed)\n",
    "print('result of closed form: \\n', resultClosed)\n",
    "print('error of closed form: \\n', errorClosed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of gradient descent: \n",
      " [[ 0.37533109]\n",
      " [-1.07323872]\n",
      " [-0.22619048]\n",
      " [ 0.8207526 ]]\n",
      "error of gradient descent: \n",
      " 1.020380306032347\n"
     ]
    }
   ],
   "source": [
    "resultGradient = gradientDescentLinearRegression(lambda v: float(0.0020 / (float(v) + 7.0)), trainFeatures[0], trainFeatures[1], 0.00000005)\n",
    "errorGradient = meanSquareError(validationFeatures[0], validationFeatures[1], resultGradient)\n",
    "print('result of gradient descent: \\n', resultGradient)\n",
    "print('error of gradient descent: \\n', errorGradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同志们 在上面的学习率上做文章 runtime或者error做个plot 变上面根本算不完 变下面会改变第二个参数的精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== ] 99%"
     ]
    }
   ],
   "source": [
    "trainFeatures60 = parseFeatures(data[:10000], wordCountNaive, 60, ['children', 'controv', 'isRoot', 'text'])\n",
    "trainFeatures160 = parseFeatures(data[:10000], wordCountNaive, 160, ['children', 'controv', 'isRoot', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== ] 99%"
     ]
    }
   ],
   "source": [
    "validationFeatures60 = parseFeatures(data[10000:11000], wordCountNaive, 60, ['children', 'controv', 'isRoot', 'text'])\n",
    "validationFeatures160 = parseFeatures(data[10000:11000], wordCountNaive, 160, ['children', 'controv', 'isRoot', 'text'])\n",
    "testFeatures = parseFeatures(data[11000:12000], wordCountNaive, 0, ['children', 'controv', 'isRoot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 60 text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of closed form: \n",
      " [[ 3.74695111e-01]\n",
      " [-1.07354143e+00]\n",
      " [-2.16278073e-01]\n",
      " [-3.74625972e-02]\n",
      " [ 3.35057173e-02]\n",
      " [ 5.42286919e-02]\n",
      " [-4.65511800e-03]\n",
      " [ 3.52655606e-02]\n",
      " [ 3.67568792e-02]\n",
      " [-2.36741535e-03]\n",
      " [-3.32498864e-02]\n",
      " [ 3.38107071e-02]\n",
      " [-6.57306126e-02]\n",
      " [ 8.40728202e-02]\n",
      " [-2.57365907e-02]\n",
      " [-3.48272242e-04]\n",
      " [-1.35075864e-01]\n",
      " [ 5.51683049e-02]\n",
      " [ 9.14630439e-02]\n",
      " [ 2.20669528e-02]\n",
      " [ 4.49629169e-02]\n",
      " [-1.34218588e-01]\n",
      " [ 4.79114561e-02]\n",
      " [-1.04406934e-02]\n",
      " [ 1.95238650e-01]\n",
      " [-2.59536564e-01]\n",
      " [-5.80273190e-02]\n",
      " [ 4.40873129e-02]\n",
      " [ 2.66166704e-03]\n",
      " [-1.55967309e-01]\n",
      " [ 3.36928714e-01]\n",
      " [ 1.34490483e-02]\n",
      " [-3.01344520e-01]\n",
      " [ 2.66384375e-01]\n",
      " [-3.25259178e-01]\n",
      " [ 3.43536255e-01]\n",
      " [-1.95814207e-01]\n",
      " [-2.68266288e-02]\n",
      " [ 2.29292745e-01]\n",
      " [ 1.31799879e-01]\n",
      " [-4.30661088e-01]\n",
      " [ 1.25336300e-02]\n",
      " [ 3.28200816e-01]\n",
      " [-2.69265890e-02]\n",
      " [-4.84179116e-01]\n",
      " [-1.14722496e-01]\n",
      " [ 2.63881844e-01]\n",
      " [-3.94260506e-02]\n",
      " [-8.67481750e-02]\n",
      " [ 2.40714213e-01]\n",
      " [-4.27759819e-02]\n",
      " [ 2.11332892e-01]\n",
      " [-3.39047484e-01]\n",
      " [-9.52728784e-02]\n",
      " [ 3.31745659e-01]\n",
      " [-6.33189898e-02]\n",
      " [-5.78054491e-02]\n",
      " [ 2.47968691e-01]\n",
      " [-2.11653186e-01]\n",
      " [ 4.87781069e-01]\n",
      " [-5.39521758e-01]\n",
      " [ 1.68603865e-01]\n",
      " [-1.23625363e-01]\n",
      " [ 7.56484442e-01]]\n",
      "error of closed form: \n",
      " 1.0165811112679506\n"
     ]
    }
   ],
   "source": [
    "resultClosed = closedFormLinearRegression(trainFeatures60[0], trainFeatures60[1])\n",
    "errorClosed = meanSquareError(validationFeatures60[0], validationFeatures60[1], resultClosed)\n",
    "print('result of closed form: \\n', resultClosed)\n",
    "print('error of closed form: \\n', errorClosed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of closed form: \n",
      " [[ 2.74232176e+12]\n",
      " [-9.06833492e+14]\n",
      " [ 1.15999077e+14]\n",
      " [-9.49426268e+14]\n",
      " [ 8.73215246e+14]\n",
      " [ 1.21212310e+15]\n",
      " [ 2.04233915e+14]\n",
      " [ 2.82435390e+14]\n",
      " [-1.48346474e+14]\n",
      " [ 2.82250587e+15]\n",
      " [-1.38041914e+14]\n",
      " [ 7.02132841e+13]\n",
      " [ 4.93506165e+14]\n",
      " [ 1.40323422e+14]\n",
      " [-1.12171375e+13]\n",
      " [-4.86086136e+14]\n",
      " [ 6.73320940e+13]\n",
      " [ 1.69584555e+14]\n",
      " [ 3.53008477e+15]\n",
      " [-2.60711784e+14]\n",
      " [ 2.33603085e+14]\n",
      " [-2.10285265e+15]\n",
      " [ 3.40462048e+15]\n",
      " [-8.02016028e+13]\n",
      " [ 1.47081636e+14]\n",
      " [-1.90712198e+14]\n",
      " [-9.49324495e+13]\n",
      " [ 4.39961420e+13]\n",
      " [ 7.55113532e+13]\n",
      " [-4.18799069e+13]\n",
      " [ 1.66923500e+15]\n",
      " [-1.14587116e+15]\n",
      " [-5.67051006e+15]\n",
      " [-2.50218789e+16]\n",
      " [ 1.42236439e+15]\n",
      " [-2.71469951e+15]\n",
      " [ 7.47446728e+16]\n",
      " [-6.36622143e+14]\n",
      " [ 5.57101440e+14]\n",
      " [ 1.74864715e+16]\n",
      " [ 9.66474130e+14]\n",
      " [ 4.61024317e+16]\n",
      " [ 2.93970200e+14]\n",
      " [-3.20754812e+13]\n",
      " [ 1.55152452e+14]\n",
      " [-2.25414452e+14]\n",
      " [ 2.02995354e+13]\n",
      " [ 1.00560808e+14]\n",
      " [ 1.45518067e+13]\n",
      " [ 1.07872895e+13]\n",
      " [-2.15041201e+15]\n",
      " [ 6.81391953e+13]\n",
      " [ 1.48896760e+16]\n",
      " [ 1.05758644e+16]\n",
      " [ 2.10173971e+14]\n",
      " [-7.11849269e+13]\n",
      " [-4.89307014e+13]\n",
      " [-5.42818495e+13]\n",
      " [-7.73039288e+11]\n",
      " [-9.22861534e+14]\n",
      " [-1.11961811e+15]\n",
      " [-8.00849768e+13]\n",
      " [ 2.40407601e+15]\n",
      " [ 9.61441143e+13]\n",
      " [ 8.20269984e+16]\n",
      " [-1.97569119e+17]\n",
      " [ 3.70373297e+17]\n",
      " [ 1.29432084e+18]\n",
      " [ 5.11369688e+16]\n",
      " [-1.13391801e+18]\n",
      " [ 5.54482830e+18]\n",
      " [-1.85353262e+17]\n",
      " [ 7.43565316e+17]\n",
      " [-1.13491577e+18]\n",
      " [ 1.06189434e+18]\n",
      " [ 3.49352544e+16]\n",
      " [ 8.70367416e+17]\n",
      " [ 1.45961494e+18]\n",
      " [-5.67564655e+17]\n",
      " [-1.43631293e+20]\n",
      " [ 7.89558333e+16]\n",
      " [ 5.31402769e+18]\n",
      " [ 9.86301481e+15]\n",
      " [ 1.56596280e+17]\n",
      " [-2.63034235e+15]\n",
      " [-8.82174123e+17]\n",
      " [-1.62225899e+18]\n",
      " [-6.07438800e+14]\n",
      " [ 1.07343977e+16]\n",
      " [ 3.41126401e+16]\n",
      " [ 7.98367696e+16]\n",
      " [-1.37486179e+19]\n",
      " [-1.76128001e+15]\n",
      " [ 4.23244256e+16]\n",
      " [ 3.98668265e+14]\n",
      " [ 3.90727856e+15]\n",
      " [ 3.60211459e+13]\n",
      " [-8.55733558e+16]\n",
      " [-1.92195103e+17]\n",
      " [ 3.73860647e+16]\n",
      " [ 2.75186468e+15]\n",
      " [ 9.56695112e+16]\n",
      " [-5.19120381e+18]\n",
      " [-2.25678880e+16]\n",
      " [ 1.07590998e+19]\n",
      " [-4.26903902e+17]\n",
      " [-1.16484131e+16]\n",
      " [ 5.68401553e+17]\n",
      " [-5.38390613e+17]\n",
      " [-1.31165125e+17]\n",
      " [-1.12438960e+18]\n",
      " [ 6.96375884e+18]\n",
      " [ 2.10523156e+14]\n",
      " [-6.33481868e+16]\n",
      " [ 1.32246162e+16]\n",
      " [ 2.33524267e+16]\n",
      " [ 0.00000000e+00]\n",
      " [-1.19710058e+17]\n",
      " [-9.51688119e+17]\n",
      " [ 2.76908019e+18]\n",
      " [-2.03274788e+16]\n",
      " [-1.26459159e+16]\n",
      " [ 8.71987333e+31]\n",
      " [ 3.00060377e+32]\n",
      " [-2.12974323e+16]\n",
      " [-2.62145312e+16]\n",
      " [ 1.65409790e+16]\n",
      " [-1.27067166e+16]\n",
      " [-1.46075959e+20]\n",
      " [-3.34196050e+17]\n",
      " [-9.68715909e+19]\n",
      " [-5.45034294e+34]\n",
      " [ 3.68915608e+34]\n",
      " [ 9.99835822e+33]\n",
      " [-2.54119459e+18]\n",
      " [ 3.18930040e+16]\n",
      " [ 3.36885302e+19]\n",
      " [-2.34967963e+17]\n",
      " [ 1.86688155e+15]\n",
      " [-2.81108831e+16]\n",
      " [-1.19720734e+35]\n",
      " [ 1.30608487e+35]\n",
      " [ 7.16053584e+17]\n",
      " [-9.70927124e+15]\n",
      " [ 2.05363402e+15]\n",
      " [-1.93037338e+16]\n",
      " [-9.69732154e+16]\n",
      " [ 1.02687909e+16]\n",
      " [ 2.30482168e+34]\n",
      " [-3.09618197e+33]\n",
      " [ 6.63113649e+32]\n",
      " [-1.26559954e+16]\n",
      " [ 2.17249100e+16]\n",
      " [-1.13237153e+32]\n",
      " [ 2.08594010e+16]\n",
      " [-8.67051714e+29]\n",
      " [ 1.72059060e+29]\n",
      " [-4.00785644e+15]\n",
      " [ 1.98067087e+14]\n",
      " [-3.12511580e+14]\n",
      " [-3.04148806e+15]\n",
      " [-3.76419236e+15]\n",
      " [-1.01743768e+14]\n",
      " [-8.69063477e+13]]\n",
      "error of closed form: \n",
      " 6.02217226504286e+66\n"
     ]
    }
   ],
   "source": [
    "resultClosed160 = closedFormLinearRegression(trainFeatures160[0], trainFeatures160[1])\n",
    "errorClosed160 = meanSquareError(validationFeatures160[0], validationFeatures160[1], resultClosed160)\n",
    "print('result of closed form: \\n', resultClosed160)\n",
    "print('error of closed form: \\n', errorClosed160)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================== ] 99%"
     ]
    }
   ],
   "source": [
    "trainFeaturesMy = parseFeatures(data[:10000], wordCountNaive, 0, ['children', 'controv', 'isRoot', 'noun', 'verb', 'adj', 'url'])\n",
    "validationFeaturesMy = parseFeatures(data[10000:11000], wordCountNaive, 0, ['children', 'controv', 'isRoot', 'noun', 'verb', 'adj', 'url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.savetxt('bossliTrainX', trainFeaturesMy[0])\n",
    "numpy.savetxt('bossliTrainY', trainFeaturesMy[1])\n",
    "numpy.savetxt('bossliValidX', validationFeaturesMy[0])\n",
    "numpy.savetxt('bossliValidY', validationFeaturesMy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of closed form: \n",
      " [[ 0.37363417]\n",
      " [-1.08690432]\n",
      " [-0.21653133]\n",
      " [-0.31941212]\n",
      " [-0.06040168]\n",
      " [-0.0315679 ]\n",
      " [ 0.38325199]\n",
      " [ 0.87533718]]\n",
      "error of closed form: \n",
      " 1.009325296525023\n"
     ]
    }
   ],
   "source": [
    "resultClosedMy = closedFormLinearRegression(trainFeaturesMy[0], trainFeaturesMy[1])\n",
    "errorClosedMy = meanSquareError(validationFeaturesMy[0], validationFeaturesMy[1], resultClosedMy)\n",
    "print('result of closed form: \\n', resultClosedMy)\n",
    "print('error of closed form: \\n', errorClosedMy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
